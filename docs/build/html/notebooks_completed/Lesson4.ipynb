{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18d50cc",
   "metadata": {},
   "source": [
    "# üìö Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545c946-db60-4664-8e18-52ad2f93a270",
   "metadata": {},
   "source": [
    "Available: Saturday, 15 March @ 0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faabcb55-affe-4497-a776-1c0d8578ac5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T05:31:16.541495Z",
     "iopub.status.busy": "2025-02-24T05:31:16.540792Z",
     "iopub.status.idle": "2025-02-24T05:31:16.560321Z",
     "shell.execute_reply": "2025-02-24T05:31:16.557660Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'üìå' (U+1F4CC) (3169125495.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    üìå **For a beginner-friendly Intro to Python for Data Analysis, check out:**\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character 'üìå' (U+1F4CC)\n"
     ]
    }
   ],
   "source": [
    "A key focus of this lesson is **data in Python**, which will set the stage for later technical components of this course. Python is a powerful tool for data analysis, and throughout this course, we will leverage libraries such as `pandas`, `numpy`, and `matplotlib` to work with different types of data. This lesson introduces core data concepts while also familiarizing you with Python-specific data types and structures.  \n",
    "\n",
    "üìå **For a beginner-friendly Intro to Python for Data Analysis, check out:**  \n",
    "[Python for Data Analysis YouTube Playlist by Data Daft](https://www.youtube.com/playlist?list=PLiC1doDIe9rCYWmH9wIEYEXXaJ4KAi3jc)  \n",
    "This playlist offers digestible explanations of Python‚Äôs core data analysis features and is a great supplementary resource.  We'll be incorporating some of their lessons into this course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad40b3b-7b9e-46c1-a93b-159cf45604bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T05:31:16.567462Z",
     "iopub.status.busy": "2025-02-24T05:31:16.566758Z",
     "iopub.status.idle": "2025-02-24T05:31:16.579560Z",
     "shell.execute_reply": "2025-02-24T05:31:16.578265Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1556709146.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    **Why Python for Data Analysis?**\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "**Why Python for Data Analysis?** \n",
    "\n",
    "Python is widely used in data science and MDM analysis because it provides:  \n",
    "\n",
    "- **Flexibility**: Python can handle structured and unstructured data, making it ideal for analyzing social media posts, news articles, and survey data.  \n",
    "- **Powerful Libraries**: Packages like `pandas` for data manipulation, `numpy` for numerical operations, and `matplotlib` for visualization simplify analysis.  \n",
    "- **Automation**: Python allows us to automate data collection, preprocessing, and visualization, making large-scale MDM analysis feasible.  \n",
    "- **Integration**: Python seamlessly integrates with APIs, databases, and web scraping tools, making it easier to acquire real-world MDM-related data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5bf1a-ccc8-4453-aad3-da0f055e0482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef02048-5088-4d0e-8a5d-bfc58ab8d76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f662faa8-9aac-429b-88e8-ac35eb8e28a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3491d8a4",
   "metadata": {},
   "source": [
    " Understanding the Problem: A Critical First Step\n",
    "\n",
    "Before diving into data collection and analysis, it is essential to fully understand the misinformation problem we are investigating. A well-defined problem ensures that our research remains focused, actionable, and impactful. \n",
    "\n",
    " Why Is Understanding the Problem Important?\n",
    "\n",
    "Misidentifying the problem can lead to wasted resources, misleading conclusions, and ineffective interventions. In misinformation research, failing to define the problem properly can result in:\n",
    "\n",
    "- **Data Overload:** Collecting excessive, unfocused data that is difficult to analyze.\n",
    "- **Misinterpretation of Findings:** Drawing incorrect conclusions by analyzing data that does not align with the core research question.\n",
    "- **Ineffective Solutions:** Proposing interventions that do not address the root causes of misinformation.\n",
    "\n",
    "To mitigate these risks, researchers must take a step back and clarify what they are trying to study before collecting data.\n",
    "\n",
    " Key Considerations in Defining the Problem\n",
    "\n",
    "When investigating misinformation, consider these critical questions:\n",
    "\n",
    "- **What specific misinformation topic or narrative are we studying?** (e.g., COVID-19 vaccine misinformation, election fraud claims)\n",
    "- **What are the characteristics of the misinformation we are examining?** (e.g., misleading headlines, fabricated statistics, deepfakes)\n",
    "- **Who is spreading it?** (e.g., individuals, bot networks, foreign influence campaigns)\n",
    "- **How is it spreading?** (e.g., social media, traditional news, word-of-mouth)\n",
    "- **What is its impact?** (e.g., behavioral changes, public health risks, political polarization)\n",
    "\n",
    "By answering these questions, we refine our understanding and establish a clear research direction.\n",
    "\n",
    " Formulating a Research Question\n",
    "\n",
    "Once the problem is well understood, the next step is to develop a clear and specific research question. A well-formulated research question ensures that data collection and analysis remain focused and actionable.\n",
    "\n",
    " Characteristics of a Strong Research Question\n",
    "\n",
    "A good research question should be:\n",
    "\n",
    "- **Specific:** Clearly define the scope and focus of the research.\n",
    "- **Measurable:** The question should be answerable using quantifiable data.\n",
    "- **Actionable:** The findings should provide insights that can inform decision-making.\n",
    "\n",
    " Example Research Questions\n",
    "\n",
    "| Broad Question | Refined, Data-Driven Question |\n",
    "|---------------|--------------------------------|\n",
    "| How does misinformation about COVID-19 vaccines spread? | How does the engagement (likes, shares) of COVID-19 misinformation tweets differ across geographic regions? |\n",
    "| Who spreads false vaccine claims? | What is the relationship between a user's follower count and the likelihood of their tweet being shared? |\n",
    "| How effective is fact-checking? | Do tweets containing COVID-19 fact-checking information receive more or less engagement than misinformation tweets? |\n",
    "| Which groups are most affected? | Which geographic locations show the highest engagement with COVID-19 misinformation tweets? |\n",
    "\n",
    "By refining broad questions into specific, measurable, and actionable research questions, we create a strong foundation for data collection and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b3873",
   "metadata": {},
   "source": [
    " üîç Our Focused Research Question Moving Forward\n",
    "\n",
    "We've explored the problem and refined our research questions - let's focus on one specific research question for the upcoming lessons:\n",
    "\n",
    "\"How does the engagement (likes, shares) of COVID-19 misinformation tweets differ across geographic regions?\"\n",
    "\n",
    "üìå Why This Question?\n",
    "\n",
    "    Location-based analysis allows us to compare misinformation engagement trends across different regions.\n",
    "    Engagement metrics (likes, shares) help us quantify the spread and influence of misinformation.\n",
    "    Structured and measurable data makes it ideal for visualization and trend analysis.\n",
    "\n",
    "üîπ As we move forward with this lesson, we will walk through data identification, acquisition and analysis steps using this research question as our guiding example. üöÄ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d74a039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T05:31:16.585446Z",
     "iopub.status.busy": "2025-02-24T05:31:16.584725Z",
     "iopub.status.idle": "2025-02-24T05:31:16.596525Z",
     "shell.execute_reply": "2025-02-24T05:31:16.595548Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (32784406.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Question 1: Best Research Question Selection\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " Question 1: Best Research Question Selection\n",
    "create_multiple_choice(\n",
    "    \"Which of the following is the BEST example of a structured, data-driven research question?\",\n",
    "    [\n",
    "        \"A) Why do people believe COVID-19 vaccine misinformation?\",\n",
    "        \"B) How does misinformation affect people's health choices?\",\n",
    "        \"C) What is the engagement difference between COVID-19 vaccine misinformation tweets and their fact-checked corrections?\",\n",
    "        \"D) Why are people hesitant to get vaccinated?\"\n",
    "    ],\n",
    "    \"C) What is the engagement difference between COVID-19 vaccine misinformation tweets and their fact-checked corrections?\"\n",
    ")\n",
    "\n",
    " Question 2: Identifying a Weak Research Question\n",
    "create_multiple_choice(\n",
    "    \"Which of these is a weak research question for misinformation analysis?\",\n",
    "    [\n",
    "        \"A) Which Twitter accounts were most active in spreading COVID-19 vaccine misinformation between March 2020 and March 2022?\",\n",
    "        \"B) What percentage of misinformation engagement comes from bot accounts vs. real users?\",\n",
    "        \"C) Why do people share false information?\",\n",
    "        \"D) How does engagement with misinformation compare to engagement with fact-checks?\"\n",
    "    ],\n",
    "    \"C) Why do people share false information?\"\n",
    ")\n",
    "\n",
    " Question 3: Selecting the Right Research Question for Bot Detection\n",
    "create_multiple_choice(\n",
    "    \"If you want to study how bots amplify COVID-19 vaccine misinformation, which research question is most appropriate?\",\n",
    "    [\n",
    "        \"A) What are the most common emotional triggers used in vaccine misinformation?\",\n",
    "        \"B) What percentage of accounts spreading vaccine misinformation on Twitter are bots?\",\n",
    "        \"C) What are the political beliefs of people who share misinformation?\",\n",
    "        \"D) How does vaccine misinformation compare between Twitter and Facebook?\"\n",
    "    ],\n",
    "    \"B) What percentage of accounts spreading vaccine misinformation on Twitter are bots?\"\n",
    ")\n",
    "\n",
    " Question 4: Matching Data Sources to Research Questions\n",
    "create_multiple_choice(\n",
    "    \"Which dataset would BEST help answer the question: 'Which narratives gained the most traction in COVID-19 vaccine misinformation?'\",\n",
    "    [\n",
    "        \"A) Kaggle COVID-19 Fake News Dataset\",\n",
    "        \"B) Twitter API for tweet engagement metrics\",\n",
    "        \"C) Google Fact Check API\",\n",
    "        \"D) Botometer API\"\n",
    "    ],\n",
    "    \"B) Twitter API for tweet engagement metrics\"\n",
    ")\n",
    "\n",
    " Question 5: Refining Research Questions\n",
    "create_multiple_choice(\n",
    "    \"Which of the following broad research questions has been correctly refined into a data-driven research question?\",\n",
    "    [\n",
    "        \"A) Why do people believe misinformation? ‚Üí How does misinformation affect people's emotions?\",\n",
    "        \"B) How does misinformation spread online? ‚Üí Which Twitter accounts were most active in sharing COVID-19 vaccine misinformation between Mar and Apr?\",\n",
    "        \"C) Who spreads misinformation? ‚Üí What makes someone share misinformation?\",\n",
    "        \"D) How effective is fact-checking? ‚Üí Why do people ignore fact-checks?\"\n",
    "    ],\n",
    "    \"B) How does misinformation spread online? ‚Üí Which Twitter accounts were most active in sharing COVID-19 vaccine misinformation between Mar and Apr?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2018d",
   "metadata": {},
   "source": [
    "<img src=\"Images\\data identification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86897c21",
   "metadata": {},
   "source": [
    " üîπ Data Identification: Finding the Right Data for Analysis\n",
    "\n",
    "Once we have defined the problem and formulated a research question, the next step is to determine what data is needed to analyze it effectively. Not all data is equally useful, and selecting the right datasets ensures the validity and reliability of our findings.\n",
    "\n",
    " Identifying Key Data Sources\n",
    "\n",
    "To analyze misinformation, we need to collect relevant and structured data from sources where misinformation is actively spread and discussed. Common sources include:\n",
    "\n",
    "üü¢ **Social Media Platforms** (e.g., Twitter, Facebook, TikTok, Reddit) \n",
    "  - Useful for tracking how misinformation spreads and its engagement levels.\n",
    "  - Data points: post content, user engagement (likes, shares, comments), timestamps, geolocation.\n",
    "\n",
    "üü¢ **News & Fact-Checking Databases** (e.g., PolitiFact, Snopes, FactCheck.org)\n",
    "  - Helps validate misinformation claims and compare false information with factual corrections.\n",
    "  - Data points: claim description, verification status, publication date, source.\n",
    "\n",
    "üü¢ **Surveys & Polls**\n",
    "  - Measures public perception and belief in misinformation.\n",
    "  - Data points: demographics, misinformation exposure, behavioral impact.\n",
    "\n",
    "üü¢ **Metadata & Network Analysis**\n",
    "  - Identifies bot networks and coordinated campaigns.\n",
    "  - Data points: user connections, retweet patterns, account creation dates.\n",
    "\n",
    " Example Good Data for Various Topics\n",
    "\n",
    "| Research Question | Example Good Data Sources | Key Data Points |\n",
    "|------------------|------------------------|----------------|\n",
    "| How does misinformation engagement vary by platform? | Twitter API, Facebook Graph API, TikTok Data | Platform type, engagement metrics (likes, shares), misinformation content |\n",
    "| How do coordinated disinformation campaigns operate? | Open-source intelligence (OSINT), Botometer, CrowdTangle | Network connections, bot detection markers, retweet/share patterns |\n",
    "| What misinformation narratives about elections are most prevalent? | Election Integrity Partnership, MediaCloud, Twitter API | Misinformation topic, source credibility, user engagement |\n",
    "| What factors contribute to vaccine hesitancy? | WHO Vaccine Misinformation Reports, Pew Research Surveys, Facebook Data | Misinformation topic, sentiment analysis, user demographics |\n",
    "| How effective is fact-checking? | FactCheck.org, Snopes, PolitiFact | Claim description, verification status, engagement metrics |\n",
    "\n",
    "By aligning our data sources with our research question, we ensure that our analysis is evidence-based and well-supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a305d96a",
   "metadata": {},
   "source": [
    " Based on our research question‚Äî  \n",
    "**\"How does the engagement (likes, shares) of COVID-19 misinformation tweets differ across geographic regions?\"\n",
    "**‚Äî  \n",
    "we need a dataset that contains:\n",
    "\n",
    "‚úÖ Misinformation and fact-checked content on COVID 19\n",
    "\n",
    "‚úÖ Engagement metrics (likes, shares, retweets, comments, etc.) on different social media platforms\n",
    "\n",
    "‚úÖ Temporal data (timestamps for tracking trends over time and identifying peak misinformation periods)\n",
    "\n",
    "‚úÖ Geolocation data (country, region, or city-level information to analyze geographic differences)\n",
    "\n",
    "‚úÖ User metadata (follower count, account type, potential bot indicators) to assess influence on engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b5a75",
   "metadata": {},
   "source": [
    "üöÄ **Next Up:** How do we collect the right misinformation data? Let‚Äôs dive into **Data Acquisition ‚Äì Where and How Do We Collect Data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4489c09",
   "metadata": {},
   "source": [
    "<img src=\"Images\\data acquisition.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68952bcc",
   "metadata": {},
   "source": [
    " üîπ Data Acquisition ‚Äì Where and How Do We Collect Misinformation Data?\n",
    "\n",
    " üìå Why This Step Matters  \n",
    "\n",
    "Now that we‚Äôve **defined what we want to analyze** and **identified the type of data we need**, we need to determine **where to find the data** to answer our research question.\n",
    "\n",
    "Effective **data acquisition** ensures we gather **reliable, relevant, and actionable** information while avoiding incomplete or biased datasets.\n",
    "\n",
    "In this section, we‚Äôll explore:\n",
    "\n",
    "‚úÖ **Primary vs. Secondary Data Sources** ‚Äì What‚Äôs the difference, and when should we use them?  \n",
    "\n",
    "‚úÖ **Common Misinformation Data Sources** ‚Äì Where do we get structured and unstructured data?  \n",
    "\n",
    "‚úÖ **Challenges in Data Collection** ‚Äì What are the ethical, technical, and accessibility concerns?  \n",
    "\n",
    "---\n",
    "\n",
    " üîç **1: Primary vs. Secondary Data Sources**  \n",
    "\n",
    "Not all data is collected the same way. We can obtain misinformation-related data from **two main sources**:\n",
    "\n",
    "| **Data Type**      | **Definition** | **Example for MDM Analysis** | **Pros** | **Cons** |\n",
    "|-------------------|--------------|--------------------------|----------|----------|\n",
    "| **Primary Data**  | Data you collect directly through APIs, surveys, experiments, or web scraping. | Using **Twitter API** to extract misinformation tweets. | ‚úÖ Customizable, ‚úÖ More control over accuracy. | ‚ùå Requires technical setup, ‚ùå May have platform restrictions. |\n",
    "| **Secondary Data** | Data collected by external organizations or researchers and made publicly available. | Using **fact-checking databases** like Snopes or Google Fact Check Explorer. | ‚úÖ Easy access, ‚úÖ Less resource-intensive. | ‚ùå May be outdated, ‚ùå May not fit your exact research question. |\n",
    "\n",
    "---\n",
    "\n",
    " üõ†Ô∏è **2: Common MDM Data Sources**  \n",
    "\n",
    "Now, let‚Äôs explore some of the best sources for **collecting misinformation-related data**.\n",
    "\n",
    " **1Ô∏è‚É£ Social Media Data (Primary Data)**\n",
    "üü¢ **Best for:** Analyzing misinformation spread, engagement, bot activity, or amplification tactics.\n",
    "\n",
    "| **Platform**          | **How to Collect Data** | **Example Use Case** |\n",
    "|----------------------|----------------------|---------------------|\n",
    "| **Twitter**         | API access via Twitter Developer Portal | Track how a specific false narrative spreads. |\n",
    "| **Facebook & Instagram** | Meta‚Äôs CrowdTangle tool (limited availability) | Measure engagement on misinformation posts. |\n",
    "| **Reddit**          | Reddit API or Pushshift API (historical data) | Analyze misinformation discussions in niche communities. |\n",
    "| **TikTok & YouTube** | Manual scraping (no public API for full text) | Identify influencers amplifying false narratives. |\n",
    "\n",
    "‚ö† **Considerations:**  \n",
    "üîπ Some platforms require **API access approval** (may take time).  \n",
    "üîπ **Ethical concerns** ‚Äì Ensure user privacy and compliance with platform policies.\n",
    "\n",
    "---\n",
    "\n",
    " **2Ô∏è‚É£ Fact-Checking Databases (Secondary Data)**\n",
    "üü¢ **Best for:** Comparing misinformation claims to verified information.\n",
    "\n",
    "| **Database**            | **How to Access** | **Example Use Case** |\n",
    "|------------------------|------------------|---------------------|\n",
    "| **Snopes**            | Website search   | Compare viral misinformation claims with debunks. |\n",
    "| **PolitiFact**        | API or website search | Track political misinformation trends. |\n",
    "| **Google Fact Check Explorer** | API or web search | Aggregate fact-checks across multiple sources. |\n",
    "| **Poynter IFCN**      | Database search  | Access global fact-checking organizations' reports. |\n",
    "\n",
    "üìå **Pro Tip:** Fact-checking databases are **great for validation** but don‚Äôt always provide engagement metrics (likes, shares, comments).\n",
    "\n",
    "---\n",
    "\n",
    " **3Ô∏è‚É£ Web Scraping & News Archives (Primary & Secondary)**\n",
    "üü¢ **Best for:** Collecting misinformation from news sites, forums, or blogs.\n",
    "\n",
    "| **Source Type**     | **How to Collect Data** | **Example Use Case** |\n",
    "|--------------------|----------------------|---------------------|\n",
    "| **News Sites**     | Web scraping with BeautifulSoup or Selenium | Track how misinformation headlines change over time. |\n",
    "| **Conspiracy Blogs** | Scraping tools or manual collection | Analyze how narratives evolve in alternative media. |\n",
    "| **Wikipedia Edits** | Wikipedia API | Detect misinformation in article edits. |\n",
    "\n",
    "‚ö† **Considerations:**  \n",
    "üîπ **Ethical risks** ‚Äì Scraping terms of service violations can lead to blocked access.  \n",
    "üîπ **Legality** ‚Äì Some sites prohibit automated scraping‚Äîcheck platform policies.\n",
    "\n",
    "---\n",
    "\n",
    " **4Ô∏è‚É£ Surveys & Experimental Data (Primary Data)**\n",
    "üü¢ **Best for:** Measuring public perception, belief trends, and misinformation susceptibility.\n",
    "\n",
    "| **Method**          | **How to Collect Data** | **Example Use Case** |\n",
    "|-------------------|----------------------|---------------------|\n",
    "| **Online Surveys** | Google Forms, Qualtrics, or MTurk | Measure belief in misinformation narratives. |\n",
    "| **Controlled Experiments** | Academic studies or user testing | Test misinformation susceptibility before and after fact-checking. |\n",
    "\n",
    "üìå **Pro Tip:** If conducting a survey, ensure **neutral question framing** to avoid biasing responses.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    " üìù **3: Common File Types for Storage** \n",
    "\n",
    " Why File Types Matter\n",
    "When working with data, it is essential to understand different file types, as they determine how data is stored, shared, and processed. Many datasets used in misinformation analysis come in a variety of formats, each with its own advantages and use cases.\n",
    "\n",
    " Common Data File Types\n",
    "\n",
    " **1. CSV (.csv)** ‚Äì Comma-Separated Values\n",
    "- A widely used format for structured data.\n",
    "- Stores tabular data in plain text with commas separating values.\n",
    "- Easy to process with Python using `pandas.read_csv()`.\n",
    "\n",
    " **2. Excel (.xlsx, .xls)** ‚Äì Microsoft Excel Spreadsheets\n",
    "- Commonly used for structured data with multiple sheets.\n",
    "- Supports formulas, charts, and formatting.\n",
    "- Readable in Python using `pandas.read_excel()`.\n",
    "\n",
    " **3. JSON (.json)** ‚Äì JavaScript Object Notation\n",
    "- Used for structured data, especially from APIs and web sources.\n",
    "- Stores data as key-value pairs, making it flexible.\n",
    "- Readable in Python using `json.load()` or `pandas.read_json()`.\n",
    "\n",
    " **4. SQL Databases** ‚Äì Structured Query Language\n",
    "- Stores large-scale, relational data efficiently.\n",
    "- Often used for handling misinformation datasets from multiple sources.\n",
    "- Python‚Äôs `sqlite3` or `SQLAlchemy` can query SQL databases.\n",
    "\n",
    " **5. Parquet (.parquet)** ‚Äì Optimized for Big Data\n",
    "- Columnar storage format, making it faster for big data processing.\n",
    "- Used in large-scale analytics and machine learning pipelines.\n",
    "- Readable in Python using `pandas.read_parquet()`.\n",
    "\n",
    " **6. Text Files (.txt)** ‚Äì Unstructured Text Data\n",
    "- Common for logs, reports, or raw text analysis.\n",
    "- Useful for analyzing misinformation in articles, comments, or tweets.\n",
    "- Readable using standard Python file operations (`open()`, `read()`).\n",
    "\n",
    " **Additional Considerations**\n",
    "- **APIs & Web Scraped Data:** Often comes in **JSON**, **HTML**, or **CSV** formats.\n",
    "- **PDFs:** Frequently used for government reports and academic papers, but require tools like `PyPDF2` or `pdfplumber` to extract data.\n",
    "- **HTML:** Webpage data may need `BeautifulSoup` for parsing.\n",
    "\n",
    " **Key Takeaway**\n",
    "Most file types can be read and processed using Python with the right tools. Understanding these formats is essential for effective data collection and analysis in misinformation research.\n",
    "\n",
    "\n",
    " ‚ö†Ô∏è Challenges in Data Collection\n",
    "\n",
    "When working with misinformation datasets, researchers often face three key challenges:\n",
    "\n",
    " 1Ô∏è‚É£ Accessibility & API Restrictions\n",
    "\n",
    "üîπ Some platforms (e.g., Facebook, Instagram) limit public API access, making direct misinformation collection difficult.\n",
    "\n",
    "üîπ Data licensing may prevent certain datasets from being freely used.\n",
    "\n",
    "üîπ Some sources require institutional approval (e.g., Twitter‚Äôs Academic API).\n",
    "\n",
    "üîπ Data availability varies by region‚Äîsome datasets may be inaccessible in certain countries due to government regulations.\n",
    "\n",
    "üîπ API limitations (e.g., rate limits, paywalls) can restrict the volume of data that can be collected in a given timeframe.\n",
    "\n",
    " üîπ Solution:\n",
    "‚úÖ Use alternative data sources (e.g., Reddit API is more open than Facebook).\n",
    "\n",
    "‚úÖ Partner with research institutions for data-sharing agreements.\n",
    "\n",
    "‚úÖ Apply for academic API access where possible (e.g., Twitter‚Äôs Academic Research track).\n",
    "\n",
    "‚úÖ Consider ethical web scraping techniques while ensuring compliance with platform terms of service.\n",
    "\n",
    "‚úÖ Use open-source datasets compiled by misinformation research initiatives.\n",
    "\n",
    " 2Ô∏è‚É£ Ethics & Privacy Concerns\n",
    "\n",
    "üîπ User privacy ‚Äì Collecting personally identifiable information (PII) without consent is unethical and, in some cases, illegal (e.g., GDPR, CCPA).\n",
    "\n",
    "üîπ Risk of amplification ‚Äì Sharing misinformation data without context may unintentionally spread false narratives further.\n",
    "\n",
    "üîπ Ethical concerns in web scraping ‚Äì Automated collection of social media data may violate terms of service and risk exposing user data.\n",
    "\n",
    "üîπ Misinformation impact ‚Äì Storing and analyzing sensitive topics (e.g., public health misinformation) requires responsible handling to avoid contributing to harm.\n",
    "\n",
    " üîπ Solution:\n",
    "‚úÖ Anonymize data ‚Äì Remove personal identifiers before analysis.\n",
    "\n",
    "‚úÖ Focus on aggregate insights, not individual user data.\n",
    "\n",
    "‚úÖ Clearly document data collection methods to ensure ethical transparency.\n",
    "\n",
    "‚úÖ Obtain proper consent if using survey-based misinformation research.\n",
    "\n",
    "‚úÖ Apply for Institutional Review Board (IRB) approval when working with human-related misinformation data.\n",
    "\n",
    "‚úÖ Store datasets securely and limit access to authorized researchers only.\n",
    "\n",
    " 3Ô∏è‚É£ Data Noise & Bias\n",
    "\n",
    "üîπ Not all data is relevant or high-quality ‚Äì Social media posts may contain spam, satire, or unrelated content.\n",
    "\n",
    "üîπ Algorithmic bias ‚Äì Platform engagement algorithms may skew which misinformation spreads the most.\n",
    "\n",
    "üîπ Selection bias ‚Äì Certain datasets may overrepresent specific demographics, political affiliations, or geographic regions.\n",
    "\n",
    "üîπ Missing context ‚Äì Misinformation posts may not always be labeled as such, making classification difficult.\n",
    "\n",
    "üîπ Fact-checking lag ‚Äì Real-time misinformation research may struggle with delayed fact-checking verification.\n",
    "\n",
    " üîπ Solution:\n",
    "‚úÖ Preprocess & clean data (we‚Äôll cover this in Lesson 5).\n",
    "\n",
    "‚úÖ Cross-check multiple sources to reduce platform bias.\n",
    "\n",
    "‚úÖ Use diverse datasets from multiple platforms to improve representativeness.\n",
    "\n",
    "‚úÖ Apply machine learning techniques to filter out spam, satire, and irrelevant content.\n",
    "\n",
    "‚úÖ Validate misinformation classifications by cross-referencing fact-checking databases.\n",
    "\n",
    "‚úÖ Adjust for algorithmic bias by examining platform policies and content curation practices.\n",
    "\n",
    "By addressing these challenges, researchers can ensure that misinformation data is collected and analyzed responsibly, leading to more accurate and impactful findings. üöÄ\n",
    "\n",
    "---\n",
    "\n",
    " üìã **4: Assessing Datasets**  \n",
    "\n",
    "After identifying potential data sources, it is crucial to assess their quality, reliability, and limitations before using them for analysis. Not all datasets are created equal, and selecting the wrong data can lead to bias, misinterpretation, or misleading conclusions.\n",
    "\n",
    " üìä Dataset Evaluation Rubric  \n",
    "\n",
    "To ensure a dataset is **suitable for misinformation research**, use the rubric below to **assess its quality, structure, and limitations** before proceeding.  \n",
    "\n",
    "| **Evaluation Criteria**     | **Considerations**                                                          \n",
    "|----------------------------|------------------------------------------------------------------------------\n",
    "| **Relevance**              | Does the dataset align with my research question?                           \n",
    "| **Data Type**              | Is the data **structured** (tables, metrics, engagement stats) or **unstructured** (tweets, articles, images, videos)? \n",
    "| **Reliability**            | Is the source credible (**research institute, fact-checking organizations**)? \n",
    "| **Access & Limitations**   | Does the dataset require **API access, institutional approval, or have significant restrictions**? | ‚ùå Some missing timestamps, limited geographical data |\n",
    "| **Bias & Representativeness** | Does the dataset reflect a **diverse sample** or is it skewed?            \n",
    "| **Quality & Completeness** | Does the dataset contain **missing values, duplicate data, or errors**?      \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    " **üîç Course Dataset: Kaggle COVID-19 Tweet Dataset (Modified)**  \n",
    "\n",
    "üîó [Kaggle COVID-19 Tweets](https://www.kaggle.com/datasets/kaushiksuresh147/covidvaccine-tweets)  \n",
    "File Type: CSV\n",
    "\n",
    "---\n",
    "\n",
    " üìä **Dataset Evaluation: Kaggle COVID-19 Tweet Dataset (Modified)**  \n",
    "\n",
    "| **Evaluation Criteria**     | **Considerations**                                                          | **Assessment** |\n",
    "|----------------------------|-----------------------------------------------------------------------------|---------------|\n",
    "| **Relevance**              | Does the dataset align with our research question?                          | ‚úÖ High relevance‚Äîfocuses on COVID-19 misinformation and fact-checking engagement. |\n",
    "| **Data Type**              | Is the data structured (tables, metrics) or unstructured (tweets, images)?  | üü° Semi-structured‚Äîincludes both tweets and metadata (engagement, timestamps). |\n",
    "| **Reliability**            | Is the source credible (research institutions, fact-checkers)?              | ‚úÖ Based on a widely used Kaggle dataset with verified misinformation labels. |\n",
    "| **Access & Limitations**   | Does the dataset have API restrictions, missing data, or biases?           | ‚ùå Some missing timestamps, multilingual data challenges. |\n",
    "| **Bias & Representativeness** | Does the dataset reflect diverse misinformation patterns?                 | ‚ö†Ô∏è Has gaps and distortions. |\n",
    "| **Quality & Completeness** | Does the dataset contain errors, duplicates, or missing values?            | ‚úÖ No duplicates, few missing values. |\n",
    "\n",
    "üí° **The original Kaggle dataset is structured and mostly preprocessed, making it ideal for learning, but real-world misinformation data is rarely this clean. We've introduced modifications, creating a dataset that better reflects actual challenges in data analysis.**  \n",
    "\n",
    "The **modified version** includes:  \n",
    "üîπ **Multilingual tweets** to test language detection and NLP processing.  \n",
    "üîπ **Altered timestamps** to simulate irregularities in dataset collection.  \n",
    "üîπ **Randomized engagement metrics** to introduce noise and require filtering.  \n",
    "üîπ **Additional misinformation labels** with potential misclassifications for accuracy testing.  \n",
    "\n",
    "This dataset will be used in **upcoming lessons** on **exploratory data analysis, data preprocessing, and visualization**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c07a644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T05:31:16.601323Z",
     "iopub.status.busy": "2025-02-24T05:31:16.600916Z",
     "iopub.status.idle": "2025-02-24T05:31:17.086405Z",
     "shell.execute_reply": "2025-02-24T05:31:17.085212Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_multiple_choice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_multiple_choice\u001b[49m(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven the research question: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow does misinformation about election fraud spread on Twitter?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, which dataset would be the best choice?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     [\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA) A survey on voter beliefs regarding election fraud\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB) Twitter API data containing election-related tweets and engagement metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC) Fact-checking reports from PolitiFact and Snopes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD) A dataset of government election results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     ],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB) Twitter API data containing election-related tweets and engagement metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m create_multiple_choice(\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich of the following would likely present a major challenge when trying to collect misinformation-related data from Facebook?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA) API access is restricted, making it difficult to extract large-scale misinformation data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m create_multiple_choice(\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou want to analyze bot accounts spreading misinformation about COVID-19 vaccines. Which dataset would be the most useful?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA) A dataset containing Twitter user metadata, including account age and posting frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_multiple_choice' is not defined"
     ]
    }
   ],
   "source": [
    "create_multiple_choice(\n",
    "    \"Given the research question: 'How does misinformation about election fraud spread on Twitter?', which dataset would be the best choice?\",\n",
    "    [\n",
    "        \"A) A survey on voter beliefs regarding election fraud\",\n",
    "        \"B) Twitter API data containing election-related tweets and engagement metrics\",\n",
    "        \"C) Fact-checking reports from PolitiFact and Snopes\",\n",
    "        \"D) A dataset of government election results\"\n",
    "    ],\n",
    "    \"B) Twitter API data containing election-related tweets and engagement metrics\"\n",
    ")\n",
    "create_multiple_choice(\n",
    "    \"Which of the following would likely present a major challenge when trying to collect misinformation-related data from Facebook?\",\n",
    "    [\n",
    "        \"A) API access is restricted, making it difficult to extract large-scale misinformation data\",\n",
    "        \"B) Facebook provides real-time, open access to all misinformation-related posts\",\n",
    "        \"C) Facebook data is easy to analyze because all posts are fact-checked\",\n",
    "        \"D) Facebook requires no ethical considerations when collecting misinformation data\"\n",
    "    ],\n",
    "    \"A) API access is restricted, making it difficult to extract large-scale misinformation data\"\n",
    ")\n",
    "create_multiple_choice(\n",
    "    \"You want to analyze bot accounts spreading misinformation about COVID-19 vaccines. Which dataset would be the most useful?\",\n",
    "    [\n",
    "        \"A) A dataset containing Twitter user metadata, including account age and posting frequency\",\n",
    "        \"B) A news article summarizing bot activity during the pandemic\",\n",
    "        \"C) A dataset of verified government health reports\",\n",
    "        \"D) A dataset of randomized social media posts unrelated to COVID-19\"\n",
    "    ],\n",
    "    \"A) A dataset containing Twitter user metadata, including account age and posting frequency\"\n",
    ")\n",
    "create_multiple_choice(\n",
    "    \"For the research question: 'What percentage of misinformation engagement on Twitter comes from bot accounts?', which data type would be most critical?\",\n",
    "    [\n",
    "        \"A) Survey responses from Twitter users\",\n",
    "        \"B) Metadata on Twitter accounts, including retweet patterns and bot scores\",\n",
    "        \"C) A dataset of misinformation posts fact-checked by Snopes\",\n",
    "        \"D) A historical database of political misinformation\"\n",
    "    ],\n",
    "    \"B) Metadata on Twitter accounts, including retweet patterns and bot scores\"\n",
    ")\n",
    "create_multiple_choice(\n",
    "    \"Which of the following is a key ethical concern when collecting misinformation data?\",\n",
    "    [\n",
    "        \"A) Ensuring the dataset is structured correctly\",\n",
    "        \"B) Avoiding personally identifiable information (PII) in collected data\",\n",
    "        \"C) Making sure the dataset contains a mix of factual and false information\",\n",
    "        \"D) Ensuring the dataset is large enough for meaningful analysis\"\n",
    "    ],\n",
    "    \"B) Avoiding personally identifiable information (PII) in collected data\"\n",
    ")\n",
    "\n",
    "\n",
    "create_fill_in_the_blank(\n",
    "    \"When collecting misinformation data directly from social media APIs, this is an example of a ____________ (primary or secondary) data source.\",\n",
    "    \"primary\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43259c4",
   "metadata": {},
   "source": [
    " Understanding the Problem, Data Identification, and Data Acquisition for Your Chosen Narrative\n",
    " üìå Applying What You‚Äôve Learned\n",
    "\n",
    "So far, we‚Äôve walked through a structured approach to understanding a problem, data identification, and data acquisition. Now, it‚Äôs time to apply these same steps to your own research MDM narrative.\n",
    "\n",
    "In Assignment 2, you will:\n",
    "\n",
    "‚úÖ Formulate 3-5 structured research questions based on your chosen misinformation narrative.\n",
    "\n",
    "‚úÖ Identify relevant data sources that best align with your research questions.\n",
    "\n",
    "‚úÖ Critically assess dataset quality, structure, and limitations.\n",
    "\n",
    "By completing this assignment, you will be prepared to collect, clean, and analyze misinformation data in upcoming lessons.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df974abe",
   "metadata": {},
   "source": [
    " üöÄ **Next Lesson: Data Inspection, Preprocessing, and Exploratory Data Analysis (EDA)**\n",
    "\n",
    "In the next lesson, we will:\n",
    "\n",
    "‚úî Inspect the dataset structure to understand column types, categorical vs numerical data, and overall format.\n",
    "\n",
    "‚úî Clean and preprocess our dataset to remove inconsistencies, missing values, and irrelevant data.\n",
    "\n",
    "‚úî Explore data distributions by analyzing engagement patterns, misinformation prevalence, and geographic trends.\n",
    "\n",
    "‚úî Visualize key trends using charts, histograms, and heatmaps to identify patterns in misinformation spread.\n",
    "\n",
    "‚úî Detect outliers and anomalies in engagement metrics to uncover potential bot activity or coordinated disinformation \n",
    "campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8b1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
