

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ğŸ“š NLP and Sentiment Analysis &mdash; Counter Malign Influence: Strategies, Insights, and Tools 7 March 2025 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=131bf191"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="(Optional) NLP Python Walkthrough" href="Lesson8b_Week4.html" />
    <link rel="prev" title="ğŸ“ Assignment 5" href="Assignment5_Week3.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Counter Malign Influence: Strategies, Insights, and Tools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Preparation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Syllabus.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="ZoomInfo.html">Zoom Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="GettingStarted.html">Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Week 1 Foundations of MDM:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Lesson1.html">ğŸ“š What is MDM?</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson2.html">ğŸ“š Thinking Critically against MDM</a></li>
<li class="toctree-l1"><a class="reference internal" href="Guest_Speaker1.html">ğŸ¤ Research Director, CIFAL Honolulu</a></li>
<li class="toctree-l1"><a class="reference internal" href="Assignment1.html">ğŸ“ Assignment 1</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Week 2 Detecting MDM:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Lesson3_Week2.html">ğŸ“š Data Foundations in MDM Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="Assignment2_Week2.html">ğŸ“ Assignment 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson4_Week2.html">ğŸ“š Defining the Research Question &amp; Identifying Credible Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Assignment3_Week2.html">ğŸ“ Assignment 3</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Week 3 Analyzing MDM:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Lesson5_Week3.html">ğŸ“š EDA and Patterns</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson6_Week3.html">ğŸ Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="Assignment4_Week3.html">ğŸ“ Assignment 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson7_Week3.html">ğŸ“š MDM EDA Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="Guest_Speaker2.html">ğŸ¤ Defense Threat Reduction Agency</a></li>
<li class="toctree-l1"><a class="reference internal" href="Assignment5_Week3.html">ğŸ“ Assignment 5</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Week 4 Fighting MDM (Available 29 March):</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">ğŸ“š NLP and Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson8b_Week4.html">(Optional) NLP Python Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson9_Week4.html">ğŸ“š Strategic MDM Interventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Guest_Speaker3_Week4.html">ğŸ¤ US Space Forces Indo-Pacific, Intelligence Directorate</a></li>
<li class="toctree-l1"><a class="reference internal" href="Assignment6_Week4.html">ğŸ“ Assignment 6</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Weeks 5 &amp; 6:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Challenge.html">ğŸ“ Challenge Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Guest_Speaker4.html">ğŸ¤ Joint Staff, Future Capabilities Division</a></li>
<li class="toctree-l1"><a class="reference internal" href="Guest_Speaker5.html">ğŸ¤ Career Panel</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Counter Malign Influence: Strategies, Insights, and Tools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ğŸ“š NLP and Sentiment Analysis</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/Lesson8_Week4.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ğŸ“š-NLP-and-Sentiment-Analysis">
<h1>ğŸ“š NLP and Sentiment Analysis<a class="headerlink" href="#ğŸ“š-NLP-and-Sentiment-Analysis" title="Link to this heading">ïƒ</a></h1>
<p>Watch &amp; Listen or Read Through</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Import appropriate library</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s2">&quot;kvP90w8jU1Y&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">450</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<iframe
    width="600"
    height="450"
    src="https://www.youtube.com/embed/kvP90w8jU1Y"
    frameborder="0"
    allowfullscreen

></iframe></div>
</div>
<hr class="docutils" />
<p><strong>Slides and transcripts are below</strong></p>
<p><img alt="NLPSlide1" src="../_images/Slide1.jpg" /></p>
<p>Welcome, everyone, to Lesson 8â€”our introduction to Natural Language Processing, or NLP. Today, weâ€™ll explore how NLP enables computers to interpret, understand, and generate human language. Weâ€™ll also examine how NLP intersects with MDMâ€”misinformation, disinformation, and malinformationâ€”making it a crucial tool in identifying, analyzing, and combating deceptive content online.</p>
<p><img alt="NLPSlide2" src="../_images/Slide2.jpg" /></p>
<p>So, what exactly is NLP? Itâ€™s a subfield of computer science focused on helping computers understand and work with human language. It builds on something called computational linguisticsâ€”which gives us the theo-retical framework for how language works. That includes things like syntax, semantics, morphology, and phonetics. In short: computational linguistics explains how language works, and NLP is the set of tools and techniques that lets machines use that theory in practical ways, often through
machine learning. NLP is what allows your devices to read and respond to text or speech like a human would. Pause for a moment and try to think of specific tools you might use in your day to day life that employs NLP.</p>
<p><img alt="NLPSlide3" src="../_images/Slide3.jpg" /></p>
<p>NLP is all around usâ€”even if you donâ€™t realize it. Some common tools you use every day that are powered by NLP include: Virtual assistants like Siri, Alexa, or Google Assistant. My first virtual assistant was clippy in Microsoft word which most of you are probably too young to have encountered. NLP tools also include Voice-to-text features, Autocorrect, spell check, and grammar tools, Predictive text or autocomplete, Search engines that suggest queries or rank results, Real-time subtitles, Spam
filters and priority inboxes, and translation services like Google Translate. So, youâ€™re already interacting with NLP all the time. The question is: how does it work?</p>
<p><img alt="NLPSlide4" src="../_images/Slide4.jpg" /></p>
<p>NLP usually happens in six general stages. It starts with pre-processingâ€”which is about cleaning up and standardizing the raw text. Then comes the lexical stage, where we reduce words to their simplest forms. The syntactic stage looks at grammar and structureâ€”figuring out how words relate to one another. Then we dive into semantics, which is all about extracting meaning from words and sentences. The discourse stage helps us interpret meaning across larger textsâ€”paragraphs, conversations, or
entire documents. Finally, pragmatics considers real-world context and speaker intent. This is especially important when weâ€™re looking at misleading or manipulative content. Weâ€™ll work through each of these stepsâ€”starting with pre-processing.</p>
<p><img alt="NLPSlide5" src="../_images/Slide5.jpg" /></p>
<p>Step one: Pre-processing. This is where we take raw, messy text and clean it up. Imagine youâ€™re trying to analyze a chaotic tweet filled with all-caps, hashtags, punctuation, and a suspicious URL. We want to strip out all the unnecessary noise and standardize the content. Key techniques include: Tokenization: breaking the text into individual elements like words or punctuation. Stop word removal: filtering out common words like â€œis,â€ â€œand,â€ â€œtheâ€ that donâ€™t add much meaning. Punctuation removal:
getting rid of symbols, URLs, and other non-essential characters. And finally, lowercasing, to ensure consistency. By the end, we have a cleaned-up version of the text thatâ€™s easier for a computer to work with.</p>
<p><img alt="NLPSlide6" src="../_images/Slide6.jpg" /></p>
<p>Letâ€™s try this out together. Hereâ€™s a headline and news excerpt: â€œArrow head lines: Writer suggests that the Ravens and Chiefs should swap draft picksâ€¦â€ Our first step is lowercasingâ€”making all the words uniform in case. Next, we remove punctuationâ€”getting rid of colons, commas, and periods that donâ€™t add meaning. Then we tokenizeâ€”splitting the sentence into individual words. And finally, we remove stop wordsâ€”filtering out filler words like â€œthe,â€ â€œare,â€ and â€œwithâ€ to focus on meaningful
content. What weâ€™re left with is a condensed list of meaningful termsâ€”things like â€œravens,â€ â€œchiefs,â€ â€œdraft,â€ and â€œpicks.â€ These are the core ideas the sentence is communicating.</p>
<p><img alt="NLPSlide7" src="../_images/Slide7.jpg" /></p>
<p>Letâ€™s try another one. Hereâ€™s the input: â€œTrumpâ€™s auto tariffs will hit many companies, but Elon Muskâ€™s Tesla less soâ€¦â€ Just like in the previous example, think through each step: Lowercasing, Punctuation removal, Tokenization, and Stop word removal. Once youâ€™ve done all that, what are the final, deduplicated tokens? Pause the video and try it out for yourself. This step is about distilling the text down to its essenceâ€”eliminating noise and redundancy to make the text ready for further
analysis.</p>
<p><img alt="NLPSlide8" src="../_images/Slide8.jpg" /></p>
<p>After cleaning and reducing, hereâ€™s what we end up with: â€˜trumpsâ€™, â€˜autoâ€™, â€˜tariffsâ€™, â€˜hitâ€™, â€˜manyâ€™, â€˜companiesâ€™, â€˜elonâ€™, â€˜musksâ€™, â€˜teslaâ€™â€™ and so forth. Notice how these tokens capture the core entities and actionsâ€”â€œTrump,â€ â€œtariffs,â€ â€œTesla,â€ â€œcompanies,â€ â€œfalloutâ€â€”without all the grammatical glue. These cleaned-up tokens are what weâ€™d feed into the next stages of NLP for deeper meaning extraction.</p>
<p><img alt="NLPSlide9a" src="../_images/Slide9.jpg" /></p>
<p>The second stage is the Lexical Stage, where we reduce our tokens to their simplest or root forms. There are two main techniques here: Stemming: a fast, rule-based method that cuts words down to their rootâ€”like turning â€œrunningâ€ into r-u-n-n. Itâ€™s quick but sometimes messy. And Lemmatization: a more accurate, dictionary-based method that considers contextâ€”so â€œrunningâ€ becomes simply â€œrun.â€ This preserves proper grammar and is better for tasks like sentiment analysis or chatbots. Think of
stemming as a rough cut and lemmatization as a precision trim. You might choose one over the other depending on your goal.</p>
<p><img alt="NLPSlide10" src="../_images/Slide10.jpg" /></p>
<p>Next is the Syntactic Stage, where we focus on grammar and sentence structure. This is where NLP systems figure out the roles that different words play in a sentence. Two key techniques here are: Part-of-Speech Tagging: labeling each word as a noun, verb, adjective, etcetera, and Parsing: understanding how words relate to each otherâ€”like which word is the subject vs object and the action being taken. Tools like Googleâ€™s Natural Language API use syntactic analysis to help machines interpret the
sentence structure the way a hu-man would. This helps machines grasp not just the wordsâ€”but how the words are working together.</p>
<p><img alt="NLPSlide11" src="../_images/Slide11.jpg" /></p>
<p>Now we enter the Semantic Stage, where things start to get deeper. Here, the focus is on extracting meaning from textâ€”not just individual words, but what those words actually refer to in context. We use tools like: Named Entity Recognition, or NER, to identify specific people, places, or organizations. Word Sense Disambiguation to figure out which meaning of a word is being usedâ€”like whether â€œviralâ€ refers to a disease or a social media trend. And Relationship Extraction to map out how these
entities are connected. For example, in the sentence â€œThe CDC funded secret experiments with Pfizer to suppress vaccine side effects,â€ we can identify CDC and Pfizer as entities and map their relationshipâ€”like who did what to whom.</p>
<p><img alt="NLPSlide12" src="../_images/Slide12.jpg" /></p>
<p>Semantic analysis is rich with linguistic detail. Letâ€™s walk through some of the core ele-ments. Hyponymy: When one word is a more specific instance of another. For example, â€œbioweaponâ€ is a kind of â€œweapon,â€ and â€œSVRâ€ is a type of â€œforeign intelligence organiza-tion.â€ Homonymy: When the same word has completely different meaningsâ€”like â€œmaskâ€ (a physical object) versus â€œmaskâ€ (to hide). Synonymy: Words with similar meanings, like â€œexperimentâ€ and â€œtrial,â€ or â€œpoisonâ€ and â€œtoxin.â€ These help NLP
systems identify para-phrased or restated claims. These types of word relationships are critical for detecting nu-ance, identifying misinformation, and understanding how language can be manipulated.</p>
<p><img alt="NLPSlide13" src="../_images/Slide13.jpg" /></p>
<p>Continuing with semantic elements: Antonymy is when two words mean opposite thingsâ€”like â€œrealâ€ versus â€œfakeâ€ or â€œsafeâ€ versus â€œdangerous.â€ Polysemy refers to a single word hav-ing multiple related meaningsâ€”like â€œboostâ€ meaning â€œto increase immunityâ€ or just â€œto help.â€ Meronomy is when a word refers to a part of something biggerâ€”like a â€œtireâ€ being part of a â€œcar,â€ or a â€œsentenceâ€ being part of a â€œresearch article.â€ These distinctions matter when analyzing narratives. They help systems tell the
difference between a literal versus figurative use or between related but distinct ideasâ€”vital for accurate content interpreta-tion.</p>
<p><img alt="NLPSlide14" src="../_images/Slide14.jpg" /></p>
<p>To get even more precise, we can use First-Order Predicate Logic to represent meaning in formal logic. This is especially useful in misinformation detection, where people often make sweeping or exaggerated claims. For example, the claim â€œAll vaccines cause harmâ€ would be expressed as: For all x, if x is a vaccine, then x causes harm which can be countered with the idea that there exists at least one vaccine that does not cause harm. This kind of logic-based structure helps us formalize, assess,
and even automatically flag questionable or false claims.</p>
<p><img alt="NLPSlide15" src="../_images/Slide15.jpg" /></p>
<p>Letâ€™s try applying this logic to a real-world example. The claim: â€œEvery election is rigged.â€ Pause the video and try to interpret the statements. This is a powerful tool for both human and machine-based fact-checking.</p>
<p><img alt="NLPSlide16" src="../_images/Slide16.jpg" /></p>
<p>Letâ€™s break it down. Claim: â€œEvery election is rigged.â€ In logical terms, we say: â€œFor all x, if x is an election, then x is rigged.â€ This claim leaves no room for exceptions, which is what makes it so easy to challenge with logic. So we do.. with a single counterexample: â€œThere exists an x such that x is an election, and x is not rigged.â€ If even one fair election exists, the original claim is no longer universally true. This kind of logical reasoning is incredibly useful when weâ€™re trying to
unpack extreme or false claims in misinformation and disinformation.</p>
<p><img alt="NLPSlide17" src="../_images/Slide17.jpg" /></p>
<p>Another powerful way to extract meaning is through rule-based architectures. These sys-tems use if-then logic to flag certain patterns in text. For example, a rule might say:</p>
<p>â€œIf the subject is vaccine, and the verb is cause, and the object is DNA or population, then this should be flagged as high-risk misinformation.â€ These rules are simple, transparent, and explainableâ€”perfect for building tools that moderate content or teach users how to spot misinformation. While they may not catch everything, theyâ€™re excellent for identifying known, repeated misinformation patterns.</p>
<p><img alt="NLPSlide18" src="../_images/Slide18.jpg" /></p>
<p>Semantic nets take things a step further by mapping relationships between concepts. Think of it like a mind mapâ€”youâ€™ve got nodes like â€œBill Gates,â€ â€œvaccine,â€ â€œmicrochip,â€ and â€œcon-trol,â€ and edges that describe how these concepts are linkedâ€”like â€œfunds,â€ â€œcontains,â€ â€œenables,â€ and â€œspreads.â€ Disinformation often works by linking unrelated ideas together in ways that sound plausible. Semantic networks help us trace those linkages and make them visible. This is especially useful when building
disinformation knowledge graphs that expose how narratives evolve or whoâ€™s central to their spread.</p>
<p><img alt="NLPSlide19" src="../_images/Slide19.jpg" /></p>
<p>Now letâ€™s talk about frames. Frames are mental models or worldviews that shape how we interpret information. Misinformation often relies on manipulating framesâ€”especially emotional onesâ€”to stir fear, anger, or distrust. Take these three statements about vaccines: â€œVaccines reduce transmissionâ€ framed as a health issueâ€¦ â€œVaccines are tools of population controlâ€ framed as a conspiracyâ€¦ and â€œMandatory vaccines violate our free-domâ€ framed as a freedom issue. The facts might not change, but the
framing doesâ€”affecting how people react. By recognizing frames, we can better detect bias, manipulation, and intent in the language being used.</p>
<p><img alt="NLPSlide20" src="../_images/Slide20.jpg" /></p>
<p>After understanding meaning at the word and sentence level, the next step is discourse analysisâ€”looking at meaning across longer texts like paragraphs, conversations, or so-cial media threads. Here, we focus on: Co-reference resolution: figuring out what pro-nouns like â€œitâ€ or â€œtheyâ€ refer to. Discourse parsing: identifying logical connections like cause and effect or contrast. Topic tracking: following how the subject of a discussion changes. Anaphora resolution: resolving backward-pointing
references like â€œthisâ€ or â€œthatâ€. Rhetorical structure: understanding how different parts of a message relate hierarchically.</p>
<p><img alt="NLPSlide21" src="../_images/Slide21.jpg" /></p>
<p>Letâ€™s talk about Pragmaticsâ€”the final stage of NLP. This is where machines try to figure out not just what was saidâ€¦ but what was meant. It deals with intent, social context, and re-al-world knowledge. For example, someone might say, â€œOh great, another vaccine.â€ But depending on the tone and context, that could be sincereâ€”or completely sarcastic. Prag-matic analysis involves: Speech act recognition: Is this a threat, a promise, or a question? Intent detection: Whatâ€™s the speaker trying to
doâ€”persuade, mislead, provoke? Deixis resolution: Understanding words like â€œhere,â€ â€œnow,â€ or â€œthatâ€ based on context. Implicature detection: Catching whatâ€™s implied but not directly said. Irony and sarcasm detec-tion: Which is vital for social media and satire. This level is critical for spotting manipula-tion, bias, and insinuationâ€”especially in disinformation. These employ complex algorithms we wonâ€™t go too far into detail on.</p>
<p><img alt="NLPSlide22" src="../_images/Slide22.jpg" /></p>
<p>A major application of NLPâ€”especially in the context of MDMâ€”is sentiment analysis. It helps us understand how people feel about a topic based on their language. Is the senti-ment positive, negative, or neutral? Is the language emotional or objective? Sentiment analysis can be applied to anything from tweets and comments to full articlesâ€”making it a valuable tool for identifying outrage, fear, or trust across online discourse.</p>
<p><img alt="NLPSlide23" src="../_images/Slide23.jpg" /></p>
<p>One component of sentiment analysis is polarityâ€”most often we use it to describe an emotional tone. For example: â€œVaccines save lives!â€ is a positive statement. â€œVaccines cause autism!â€ is negative. â€œIt is a vaccineâ€ is a factual, unemeotional description and therefore neutral. In this context, polarity is usually scored from negative 1 to positive 1, with 0 being neutral. It helps us flag content thatâ€™s promoting trust and health versus content thatâ€™s instilling fear, anger, or resistance.</p>
<p>But polarity can also reflect ideological direction, not just emotional tone.</p>
<p>For example, statements or entire news outlets might lean liberal or conservative.</p>
<p>You may have seen media bias charts that place outlets like NPR or The New York Times on one end, and Fox News or Breitbart on the other. NLP systems can detect this political polarity by analyzing word choice, framing, and even co-occurrence patterns.</p>
<p>So whether weâ€™re talking about emotional sentiment or political slant, polarity helps us better understand the underlying messageâ€”and how it might influence public opinion.</p>
<p><img alt="NLPSlide24" src="../_images/Slide24.jpg" /></p>
<p>The next piece is subjectivity. This measures how much of a statement is based on per-sonal opinion versus verifiable fact. For example: â€œThe article was shared over 2,000 times in 2 hoursâ€ is objective and measurable. â€œThe article was clearly designed to mis-lead the publicâ€ however, is subjective, based on judgment. Subjectivity scores range from 0 (completely objective) to 1 (highly subjective). High subjectivity often signals emotionally driven or opinionated contentâ€”something we watch
closely when analyzing MDM narratives.</p>
<p><img alt="NLPSlide25" src="../_images/Slide25.jpg" /></p>
<p>Beyond polarity and subjectivity, we can also analyze emotion and intensityâ€”what mood is being expressed, and how strongly.</p>
<p>For instance, a statement might carry emotions like fear, anger, happiness, or surpriseâ€”but those can range from mild unease to intense outrage.</p>
<p>One useful framework is the emotion wheel, originally developed by psychologist Robert Plutchik, which has evolved over time.</p>
<p>It illustrates how core emotions like joy, trust, fear, and anger can blend into more complex feelingsâ€”like anticipation turning into anxiety, or joy into pride.</p>
<p>NLP tools often use versions of this wheel to tag language not just with a single emotion, but with emotion categories and intensities, giving us a more nuanced read on what a speaker or writer is trying to evoke.</p>
<p>In MDM detection, these emotional cues are often red flagsâ€”especially when strong emotional appeals are paired with low factual content or high subjectivity.</p>
<p>Understanding sentiment in all its formsâ€”including the emotional tone, its strength, and where it sits on the wheelâ€”helps us pinpoint which messages are most likely to influence behavior or perception.</p>
<p><img alt="NLPSlide26" src="../_images/Slide26.jpg" /></p>
<p>Letâ€™s look at some examples of sentiment outputs. First, we have: â€œVaccines save mil-lions of lives every year!â€. Polarity is Positive, Subjectivity is Low, and detected Emotions include Trust and hope. Contrast that with: â€œThe government is hiding the real number of vaccine-related deathsâ€ where Polarity is Negative, Subjectivity is High, and detected Emotions include Fear and Suspicion. These examples show how NLP tools help break down the emotional tone, factual base, and intent behind
different types of content. Pause the video and judge the remaining texts.</p>
<p><img alt="NLPSlide27a" src="../_images/Slide27.jpg" /></p>
<p>Were your assessments correct? â€œWake up! Theyâ€™re injecting us with experimental chemicals to control usâ€ is Negative with high subjectivity. â€œThe article was shared over 10,000 times in less than an hourâ€ has neutral polarity with low subjectivity while â€œMandatory vaccines violate our basic human rightsâ€ has negative polarity and high subjectivity. These cases are especially important in MDM analysis because strong emo-tional language can drive engagement, virality, and beliefâ€”even when the
content isnâ€™t fac-tually accurate.</p>
<p><img alt="NLPSlide28" src="../_images/Slide28.jpg" /></p>
<p>So letâ€™s recap. We walked through all six stages of Natural Language Processingâ€”from cleaning raw text to detecting speaker intent. We explored how machines can extract mean-ing, detect patterns, and even identify emotional tone. And we learned how these tools can be used not just for automation or analyticsâ€”but for identifying and responding to MDM.</p>
<p><img alt="NLPSlide29" src="../_images/Slide29.jpg" /></p>
<p>When we combine all these toolsâ€”we can start to assign MDM risk scores to individual posts. Imagine a system that flags a post as high-risk not just because it contains false claims, but also because it uses emotional framing, subjective language, and known disinformation patterns. This is the kind of integrated analysis that powers modern moderation tools, automated fact-checkers, and even intelligence dashboards. Itâ€™s where NLP meets the real-world challenge of protecting truth and reducing
harm online.</p>
<p><img alt="NLPSlide30" src="../_images/Slide30.jpg" /></p>
<p>Thank you for engaging with this lessonâ€”I hope you now have a stronger sense of how language, data, and machine learning all come together to help us navigate complex digital landscapes.</p>
<p><a class="reference external" href="https://forms.gle/4ZRmNr5rmGCAR1Re6">Provide Anonymous Feedback on this Lesson Here</a></p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Assignment5_Week3.html" class="btn btn-neutral float-left" title="ğŸ“ Assignment 5" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Lesson8b_Week4.html" class="btn btn-neutral float-right" title="(Optional) NLP Python Walkthrough" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Chaminade University.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>